{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTACIÓN GENERAL DE LIBRERIAS Y VISUALIZACIÓN DE DATOS (matplotlib y seaborn)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as DT\n",
    "import warnings\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import requests\n",
    "import geocoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from shapely.geometry import Point, Polygon\n",
    "#from urllib2 import urlopen\n",
    "from urllib.request import urlopen\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default') \n",
    "sns.set(style=\"whitegrid\") \n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### ALGORITMOS DE MACHINE LEARNING:\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LECTURAS DE CSV YA PROCESADOS.\n",
    "train = pd.read_csv('DATA/train.csv')\n",
    "test = pd.read_csv('DATA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentamos una parte para entrenar y constatar.\n",
    "train_2016 = train.loc[train.anio == 2016]\n",
    "train_PREV = train.loc[train.anio < 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label a predecir.\n",
    "labels_2016 = np.array(train_2016['precio'])\n",
    "labels_PREV = np.array(train_PREV['precio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resto de los labels.\n",
    "train_2016 = train_2016.drop('precio', axis = 1)\n",
    "train_PREV = train_PREV.drop('precio', axis = 1)\n",
    "train_2016 = train_2016.drop('anio', axis = 1)\n",
    "train_PREV = train_PREV.drop('anio', axis = 1)\n",
    "test = test.drop('anio', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas.\n",
    "feature_list = list(train_PREV.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array\n",
    "train_2016 = np.array(train_2016)\n",
    "train_PREV = np.array(train_PREV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (145664, 12)\n",
      "Training Labels Shape: (145664,)\n",
      "Testing Features Shape: (93936, 12)\n",
      "Testing Labels Shape: (93936,)\n"
     ]
    }
   ],
   "source": [
    "# Observamos lo que nos queda en cada parte.\n",
    "print('Training Features Shape:', train_PREV.shape)\n",
    "print('Training Labels Shape:', labels_PREV.shape)\n",
    "print('Testing Features Shape:', train_2016.shape)\n",
    "print('Testing Labels Shape:', labels_2016.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos el regresor con parámetros por defecto.\n",
    "rf = RandomForestRegressor(n_estimators = 150, random_state = 75)\n",
    "# Entrenamos.\n",
    "rf.fit(train_PREV, labels_PREV);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una predicción.\n",
    "predictions = rf.predict(train_2016)\n",
    "# Calculamos el error absoluto.\n",
    "errors = abs(predictions - labels_2016)\n",
    "# Imprimimos el error.\n",
    "print('Error:', round(np.mean(errors), 2), 'grados.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el porcentaje de error.\n",
    "mape = 100 * (errors / labels_2016)\n",
    "# Calculate la precisión.\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Precision:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = rf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =================================================================================================\n",
    "## ARMAMOS EN BASE A LA PREDICCIÓN QUE TENEMOS UN CSV PARA SUBIR A KAGGLE CON EL FORMATO INDICADO!\n",
    "## =================================================================================================\n",
    "submission = pd.DataFrame({ 'id': test['id'], 'target': prediccion })\n",
    "submission.to_csv(\"SUBMITS/001_G34_RandomForest.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
