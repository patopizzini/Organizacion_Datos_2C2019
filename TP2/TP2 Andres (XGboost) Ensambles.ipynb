{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### IMPORTACIÓN GENERAL DE LA INFORMACIÓN.\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTACIÓN GENERAL DE LIBRERIAS Y VISUALIZACIÓN DE DATOS (matplotlib y seaborn)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as DT\n",
    "import warnings\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import requests\n",
    "import geocoder\n",
    "\n",
    "# Random Forest.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from shapely.geometry import Point, Polygon\n",
    "from urllib2 import urlopen\n",
    "\n",
    "# XGBoost.\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default') \n",
    "sns.set(style=\"whitegrid\") \n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### ALGORITMOS DE MACHINE LEARNING:\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LECTURAS DE CSV YA PROCESADOS.\n",
    "train = pd.read_csv('DATA/train_procesado.csv')\n",
    "test = pd.read_csv('DATA/test_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Identificador = pd.DataFrame()\n",
    "Identificador['id'] = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id', axis = 1)\n",
    "test = test.drop('id', axis = 1)\n",
    "\n",
    "train = train.drop('mean_2016', axis = 1)\n",
    "test = test.drop('mean_2016', axis = 1)\n",
    "\n",
    "train = train.drop('median_2016', axis = 1)\n",
    "test = test.drop('median_2016', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240000 entries, 0 to 239999\n",
      "Columns: 187 entries, habitaciones to mean_2016_agrupado_9\n",
      "dtypes: int64(187)\n",
      "memory usage: 342.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 186 entries, habitaciones to mean_2016_agrupado_9\n",
      "dtypes: int64(186)\n",
      "memory usage: 85.1 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resto de los labels.\n",
    "Y = np.array(train['precio'])\n",
    "X = train.drop('precio', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### XGBoost.\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODELO ENSAMBLE 1.\n",
    "trainX_M1, testX_M1, trainY_M1, testY_M1 = train_test_split(X, Y, test_size=0.3, random_state=45)\n",
    "data_dmatrix_inst = xgb.DMatrix(data=trainX_M1,label=trainY_M1)\n",
    "model1 = xgb.XGBRegressor(objective = 'reg:linear', \n",
    "                          n_estimators = 500,\n",
    "                          min_child_weight = 5,\n",
    "                          learning_rate = 0.05017181127931773,\n",
    "                          gamma = 10,\n",
    "                          reg_lambda = 3,\n",
    "                          max_depth = 9,\n",
    "                          colsample_bytree = 0.7585033814547916, \n",
    "                          subsample_bytree = 0.9779760690574663)\n",
    "model1.fit(trainX_M1,trainY_M1)\n",
    "pred_M1 = model1.predict(testX_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO ENSAMBLE 2.\n",
    "trainX_M2, testX_M2, trainY_M2, testY_M2 = train_test_split(X, Y, test_size=0.3, random_state=40)\n",
    "data_dmatrix_inst = xgb.DMatrix(data=trainX_M2,label=trainY_M2)\n",
    "model2 = xgb.XGBRegressor(objective = 'reg:linear', \n",
    "                          n_estimators = 500,\n",
    "                          min_child_weight = 5,\n",
    "                          learning_rate = 0.1,\n",
    "                          gamma = 9,\n",
    "                          reg_lambda = 2,\n",
    "                          max_depth = 7,\n",
    "                          colsample_bytree = 0.6, \n",
    "                          subsample_bytree = 0.8)\n",
    "model2.fit(trainX_M2,trainY_M2)\n",
    "pred_M2 = model2.predict(testX_M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO ENSAMBLE 3.\n",
    "trainX_M3, testX_M3, trainY_M3, testY_M3 = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "data_dmatrix_inst = xgb.DMatrix(data=trainX_M3,label=trainY_M3)\n",
    "model3 = xgb.XGBRegressor(objective = 'reg:linear', \n",
    "                          n_estimators = 500,\n",
    "                          min_child_weight = 5,\n",
    "                          learning_rate = 0.05017181127931773,\n",
    "                          gamma = 9,\n",
    "                          reg_lambda = 2,\n",
    "                          max_depth = 6,\n",
    "                          colsample_bytree = 0.7585033814547916, \n",
    "                          subsample_bytree = 0.9779760690574663)\n",
    "model3.fit(trainX_M3,trainY_M3)\n",
    "pred_M3 = model3.predict(testX_M3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO ENSAMBLE 4.\n",
    "trainX_M4, testX_M4, trainY_M4, testY_M4 = train_test_split(X, Y, test_size=0.3, random_state=40)\n",
    "data_dmatrix_inst = xgb.DMatrix(data=trainX_M4,label=trainY_M4)\n",
    "model4 =  RandomForestRegressor(n_estimators = 200, random_state = 100)\n",
    "model4.fit(trainX_M4,trainY_M4)\n",
    "pred_M4 = model4.predict(testX_M4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO ENSAMBLE 5.\n",
    "trainX_M5, testX_M5, trainY_M5, testY_M5 = train_test_split(X, Y, test_size=0.3, random_state=40)\n",
    "data_dmatrix_inst = xgb.DMatrix(data=trainX_M5,label=trainY_M5)\n",
    "model5 = xgb.XGBRegressor(objective = 'reg:linear', \n",
    "                          n_estimators = 500,\n",
    "                          min_child_weight = 5,\n",
    "                          learning_rate = 0.05017181127931773,\n",
    "                          gamma = 9,\n",
    "                          reg_lambda = 2,\n",
    "                          max_depth = 6,\n",
    "                          colsample_bytree = 0.7585033814547916, \n",
    "                          subsample_bytree = 0.9779760690574663)\n",
    "model5.fit(trainX_M5,trainY_M5)\n",
    "pred_M5 = model5.predict(testX_M5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=(pred_M1+pred_M2+pred_M3+pred_M4+pred_M5)/5\n",
    "testY = (testY_M1+testY_M2+testY_M3+testY_M4+testY_M5)/5\n",
    "# y_pred = xg_reg.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Error:', 343031.81, 'grados.')\n"
     ]
    }
   ],
   "source": [
    "# y_pred = xg_reg.predict(testX)\n",
    "# Calculamos el error absoluto.\n",
    "errors = abs(y_pred - testY)\n",
    "# Imprimimos el error.\n",
    "print('Error:', round(np.mean(errors), 2), 'grados.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Precision:', 85.8, '%.')\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el porcentaje de error.\n",
    "mape = 100 * (errors / testY)\n",
    "# Calculate la precisión.\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Precision:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediccion = xg_reg.predict(test)\n",
    "\n",
    "pred_M1_f = model1.predict(test)\n",
    "pred_M2_f = model2.predict(test)\n",
    "pred_M3_f = model3.predict(test)\n",
    "pred_M4_f = model4.predict(test)\n",
    "pred_M5_f = model5.predict(test)\n",
    "\n",
    "#prediccion = np.array([])\n",
    "#for i in range(0,len(test)):\n",
    "#    prediccion = np.append(prediccion, mode([pred_M1_f[i], pred_M2_f[i], pred_M3_f[i], pred_M4_f[i], pred_M5_f[i]]))\n",
    "\n",
    "prediccion =(pred_M1_f+pred_M2_f+pred_M3_f+pred_M4_f+pred_M5_f)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =================================================================================================\n",
    "## ARMAMOS EN BASE A LA PREDICCIÓN QUE TENEMOS UN CSV PARA SUBIR A KAGGLE CON EL FORMATO INDICADO!\n",
    "## =================================================================================================\n",
    "submission = pd.DataFrame({ 'id': Identificador['id'], 'target': prediccion })\n",
    "submission.to_csv(\"SUBMITS/012_G34_PrecioAgrupado_Ensambles_02.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
